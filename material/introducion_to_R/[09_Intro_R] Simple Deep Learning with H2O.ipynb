{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### install.packages(\"h2o\", lib=\"/opt/conda/lib/R/library\", repo=\"http://cran.us.r-project.org\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create H2O cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Connection successful!\n",
      "\n",
      "R is connected to the H2O cluster: \n",
      "    H2O cluster uptime:         22 hours 6 minutes \n",
      "    H2O cluster version:        3.10.3.6 \n",
      "    H2O cluster version age:    1 month and 14 days  \n",
      "    H2O cluster name:           H2O_started_from_R_jovyan_qjv229 \n",
      "    H2O cluster total nodes:    1 \n",
      "    H2O cluster total memory:   1.61 GB \n",
      "    H2O cluster total cores:    4 \n",
      "    H2O cluster allowed cores:  4 \n",
      "    H2O cluster healthy:        TRUE \n",
      "    H2O Connection ip:          localhost \n",
      "    H2O Connection port:        54321 \n",
      "    H2O Connection proxy:       NA \n",
      "    R Version:                  R version 3.3.2 (2016-10-31) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(h2o)\n",
    "h2o.init(\n",
    "  nthreads=-1,            ## -1: use all available threads\n",
    "  max_mem_size = \"2G\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  |                                                                            \r",
      "  |                                                                      |   0%\r",
      "  |                                                                            \r",
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "df=h2o.importFile(\"data/iris_h.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training  and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y <- \"Species\"\n",
    "x <- setdiff(names(df), y)\n",
    "parts <- h2o.splitFrame(df, 0.8, seed = 99)\n",
    "train <- parts[[1]]\n",
    "test <- parts[[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train without parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  |                                                                            \r",
      "  |                                                                      |   0%\r",
      "  |                                                                            \r",
      "  |=================================================                     |  70%\r",
      "  |                                                                            \r",
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.506   0.008   2.535 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.time(  #0.248   0.005   1.343\n",
    "m <- h2o.deeplearning(x, y, train, seed = 99, reproducible = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  |                                                                            \r",
      "  |                                                                      |   0%\r",
      "  |                                                                            \r",
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.054   0.001   0.060 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.time(  #0.031   0.002   0.069\n",
    "p <- h2o.predict(m, test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details:\n",
      "==============\n",
      "\n",
      "H2OMultinomialModel: deeplearning\n",
      "Model Key:  DeepLearning_model_R_1491313745366_7 \n",
      "Status of Neuron Layers: predicting Species, 3-class classification, multinomial distribution, CrossEntropy loss, 41,803 weights/biases, 498.6 KB, 1,200 training samples, mini-batch size 1\n",
      "  layer units      type dropout       l1       l2 mean_rate rate_rms momentum\n",
      "1     1     4     Input  0.00 %                                              \n",
      "2     2   200 Rectifier  0.00 % 0.000000 0.000000  0.003570 0.002293 0.000000\n",
      "3     3   200 Rectifier  0.00 % 0.000000 0.000000  0.011746 0.031420 0.000000\n",
      "4     4     3   Softmax         0.000000 0.000000  0.003125 0.007148 0.000000\n",
      "  mean_weight weight_rms mean_bias bias_rms\n",
      "1                                          \n",
      "2   -0.001018   0.106261  0.490440 0.006311\n",
      "3    0.000055   0.069728  0.999086 0.003699\n",
      "4   -0.007762   0.399001 -0.000217 0.001334\n",
      "\n",
      "H2OMultinomialMetrics: deeplearning\n",
      "** Reported on training data. **\n",
      "** Metrics reported on full training frame **\n",
      "\n",
      "Training Set Metrics: \n",
      "=====================\n",
      "\n",
      "Extract training frame with `h2o.getFrame(\"RTMP_sid_84be_9\")`\n",
      "MSE: (Extract with `h2o.mse`) 0.01097513\n",
      "RMSE: (Extract with `h2o.rmse`) 0.1047622\n",
      "Logloss: (Extract with `h2o.logloss`) 0.03664316\n",
      "Mean Per-Class Error: 0.01710526\n",
      "Confusion Matrix: Extract with `h2o.confusionMatrix(<model>,train = TRUE)`)\n",
      "=========================================================================\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "           setosa versicolor virginica  Error      Rate\n",
      "setosa         42          0         0 0.0000 =  0 / 42\n",
      "versicolor      0         37         1 0.0263 =  1 / 38\n",
      "virginica       0          1        39 0.0250 =  1 / 40\n",
      "Totals         42         38        40 0.0167 = 2 / 120\n",
      "\n",
      "Hit Ratio Table: Extract with `h2o.hit_ratio_table(<model>,train = TRUE)`\n",
      "=======================================================================\n",
      "Top-3 Hit Ratios: \n",
      "  k hit_ratio\n",
      "1 1  0.983333\n",
      "2 2  1.000000\n",
      "3 3  1.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scoring History: \n",
      "             timestamp   duration training_speed   epochs iterations\n",
      "1  2017-04-05 11:57:01  0.000 sec                 0.00000          0\n",
      "2  2017-04-05 11:57:01  0.169 sec    800 obs/sec  1.00000          1\n",
      "3  2017-04-05 11:57:01  0.327 sec    797 obs/sec  2.00000          2\n",
      "4  2017-04-05 11:57:02  0.489 sec    789 obs/sec  3.00000          3\n",
      "5  2017-04-05 11:57:02  0.644 sec    794 obs/sec  4.00000          4\n",
      "6  2017-04-05 11:57:02  0.792 sec    805 obs/sec  5.00000          5\n",
      "7  2017-04-05 11:57:02  0.951 sec    802 obs/sec  6.00000          6\n",
      "8  2017-04-05 11:57:02  1.104 sec    805 obs/sec  7.00000          7\n",
      "9  2017-04-05 11:57:02  1.256 sec    808 obs/sec  8.00000          8\n",
      "10 2017-04-05 11:57:02  1.411 sec    808 obs/sec  9.00000          9\n",
      "11 2017-04-05 11:57:03  1.565 sec    809 obs/sec 10.00000         10\n",
      "12 2017-04-05 11:57:03  1.575 sec    807 obs/sec 10.00000         10\n",
      "       samples training_rmse training_logloss training_classification_error\n",
      "1     0.000000                                                             \n",
      "2   120.000000       0.32895          0.37346                       0.13333\n",
      "3   240.000000       0.27215          0.22884                       0.10000\n",
      "4   360.000000       0.18219          0.12141                       0.04167\n",
      "5   480.000000       0.10703          0.04483                       0.01667\n",
      "6   600.000000       0.11393          0.04530                       0.01667\n",
      "7   720.000000       0.21363          0.16655                       0.06667\n",
      "8   840.000000       0.10476          0.03664                       0.01667\n",
      "9   960.000000       0.12404          0.05111                       0.01667\n",
      "10 1080.000000       0.11058          0.03772                       0.01667\n",
      "11 1200.000000       0.20312          0.16701                       0.06667\n",
      "12 1200.000000       0.10476          0.03664                       0.01667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix on train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o.confusionMatrix(m)\n",
    "h2o.confusionMatrix(m,test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
