{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Decision Tree and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing MLlib libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().appName(\"Spark SQL basic example\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()\n",
    "// For implicit conversions like converting RDDs to DataFrames\n",
    "import spark.implicits._\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.DecisionTreeClassificationModel\n",
    "import org.apache.spark.ml.classification.DecisionTreeClassifier\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Iris flower data set** or Fisher's Iris data set is a multivariate data set introduced by Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis\". The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimetres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val rawData = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\", \"true\").load(\"data/iris_h.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SepalLength: double (nullable = true)\n",
      " |-- SepalWidth: double (nullable = true)\n",
      " |-- PetalLength: double (nullable = true)\n",
      " |-- PetalWidth: double (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "|        5.1|       3.5|        1.4|       0.2| setosa|\n",
      "|        4.9|       3.0|        1.4|       0.2| setosa|\n",
      "|        4.7|       3.2|        1.3|       0.2| setosa|\n",
      "|        4.6|       3.1|        1.5|       0.2| setosa|\n",
      "|        5.0|       3.6|        1.4|       0.2| setosa|\n",
      "|        5.4|       3.9|        1.7|       0.4| setosa|\n",
      "|        4.6|       3.4|        1.4|       0.3| setosa|\n",
      "|        5.0|       3.4|        1.5|       0.2| setosa|\n",
      "|        4.4|       2.9|        1.4|       0.2| setosa|\n",
      "|        4.9|       3.1|        1.5|       0.1| setosa|\n",
      "|        5.4|       3.7|        1.5|       0.2| setosa|\n",
      "|        4.8|       3.4|        1.6|       0.2| setosa|\n",
      "|        4.8|       3.0|        1.4|       0.1| setosa|\n",
      "|        4.3|       3.0|        1.1|       0.1| setosa|\n",
      "|        5.8|       4.0|        1.2|       0.2| setosa|\n",
      "|        5.7|       4.4|        1.5|       0.4| setosa|\n",
      "|        5.4|       3.9|        1.3|       0.4| setosa|\n",
      "|        5.1|       3.5|        1.4|       0.3| setosa|\n",
      "|        5.7|       3.8|        1.7|       0.3| setosa|\n",
      "|        5.1|       3.8|        1.5|       0.3| setosa|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawData.printSchema()\n",
    "rawData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-------+-----------------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|         features|\n",
      "+-----------+----------+-----------+----------+-------+-----------------+\n",
      "|        5.1|       3.5|        1.4|       0.2| setosa|[5.1,3.5,1.4,0.2]|\n",
      "|        4.9|       3.0|        1.4|       0.2| setosa|[4.9,3.0,1.4,0.2]|\n",
      "|        4.7|       3.2|        1.3|       0.2| setosa|[4.7,3.2,1.3,0.2]|\n",
      "|        4.6|       3.1|        1.5|       0.2| setosa|[4.6,3.1,1.5,0.2]|\n",
      "|        5.0|       3.6|        1.4|       0.2| setosa|[5.0,3.6,1.4,0.2]|\n",
      "|        5.4|       3.9|        1.7|       0.4| setosa|[5.4,3.9,1.7,0.4]|\n",
      "|        4.6|       3.4|        1.4|       0.3| setosa|[4.6,3.4,1.4,0.3]|\n",
      "|        5.0|       3.4|        1.5|       0.2| setosa|[5.0,3.4,1.5,0.2]|\n",
      "|        4.4|       2.9|        1.4|       0.2| setosa|[4.4,2.9,1.4,0.2]|\n",
      "|        4.9|       3.1|        1.5|       0.1| setosa|[4.9,3.1,1.5,0.1]|\n",
      "|        5.4|       3.7|        1.5|       0.2| setosa|[5.4,3.7,1.5,0.2]|\n",
      "|        4.8|       3.4|        1.6|       0.2| setosa|[4.8,3.4,1.6,0.2]|\n",
      "|        4.8|       3.0|        1.4|       0.1| setosa|[4.8,3.0,1.4,0.1]|\n",
      "|        4.3|       3.0|        1.1|       0.1| setosa|[4.3,3.0,1.1,0.1]|\n",
      "|        5.8|       4.0|        1.2|       0.2| setosa|[5.8,4.0,1.2,0.2]|\n",
      "|        5.7|       4.4|        1.5|       0.4| setosa|[5.7,4.4,1.5,0.4]|\n",
      "|        5.4|       3.9|        1.3|       0.4| setosa|[5.4,3.9,1.3,0.4]|\n",
      "|        5.1|       3.5|        1.4|       0.3| setosa|[5.1,3.5,1.4,0.3]|\n",
      "|        5.7|       3.8|        1.7|       0.3| setosa|[5.7,3.8,1.7,0.3]|\n",
      "|        5.1|       3.8|        1.5|       0.3| setosa|[5.1,3.8,1.5,0.3]|\n",
      "+-----------+----------+-----------+----------+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "val assembler = new VectorAssembler().setInputCols(Array(\"SepalLength\",\"SepalWidth\",\n",
    "\"PetalLength\",\"PetalWidth\")).setOutputCol(\"features\")\n",
    "val Data = assembler.transform(rawData)\n",
    "Data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val labelIndexer = new StringIndexer().setInputCol(\"Species\").setOutputCol(\"indexedLabel\").fit(Data)\n",
    "// Automatically identify categorical features, and index them.\n",
    "// features with > 4 distinct values are treated as continuous.\n",
    "val featureIndexer = new VectorIndexer().setInputCol(\"features\").setOutputCol(\"indexedFeatures\").setMaxCategories(4) .fit(Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets (30% held out for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "[4.3,3.0,1.1,0.1,setosa,[4.3,3.0,1.1,0.1]]\n",
      "[4.4,2.9,1.4,0.2,setosa,[4.4,2.9,1.4,0.2]]\n",
      "[4.5,2.3,1.3,0.3,setosa,[4.5,2.3,1.3,0.3]]\n",
      "[4.6,3.1,1.5,0.2,setosa,[4.6,3.1,1.5,0.2]]\n",
      "[4.6,3.4,1.4,0.3,setosa,[4.6,3.4,1.4,0.3]]\n",
      "[4.7,3.2,1.3,0.2,setosa,[4.7,3.2,1.3,0.2]]\n",
      "[4.7,3.2,1.6,0.2,setosa,[4.7,3.2,1.6,0.2]]\n",
      "[4.8,3.4,1.6,0.2,setosa,[4.8,3.4,1.6,0.2]]\n",
      "[4.8,3.4,1.9,0.2,setosa,[4.8,3.4,1.9,0.2]]\n",
      "[4.9,3.0,1.4,0.2,setosa,[4.9,3.0,1.4,0.2]]\n",
      "[4.9,3.1,1.5,0.1,setosa,[4.9,3.1,1.5,0.1]]\n",
      "[4.9,3.1,1.5,0.2,setosa,[4.9,3.1,1.5,0.2]]\n",
      "[5.0,2.0,3.5,1.0,versicolor,[5.0,2.0,3.5,1.0]]\n",
      "[5.0,2.3,3.3,1.0,versicolor,[5.0,2.3,3.3,1.0]]\n",
      "[5.0,3.0,1.6,0.2,setosa,[5.0,3.0,1.6,0.2]]\n",
      "[5.0,3.3,1.4,0.2,setosa,[5.0,3.3,1.4,0.2]]\n",
      "[5.0,3.4,1.5,0.2,setosa,[5.0,3.4,1.5,0.2]]\n",
      "[5.0,3.4,1.6,0.4,setosa,[5.0,3.4,1.6,0.4]]\n",
      "[5.0,3.5,1.3,0.3,setosa,[5.0,3.5,1.3,0.3]]\n",
      "[5.0,3.5,1.6,0.6,setosa,[5.0,3.5,1.6,0.6]]\n",
      "[5.0,3.6,1.4,0.2,setosa,[5.0,3.6,1.4,0.2]]\n",
      "[5.1,3.3,1.7,0.5,setosa,[5.1,3.3,1.7,0.5]]\n",
      "[5.1,3.4,1.5,0.2,setosa,[5.1,3.4,1.5,0.2]]\n",
      "[5.1,3.7,1.5,0.4,setosa,[5.1,3.7,1.5,0.4]]\n",
      "[5.1,3.8,1.5,0.3,setosa,[5.1,3.8,1.5,0.3]]\n",
      "[5.1,3.8,1.9,0.4,setosa,[5.1,3.8,1.9,0.4]]\n",
      "[5.2,2.7,3.9,1.4,versicolor,[5.2,2.7,3.9,1.4]]\n",
      "[5.2,3.4,1.4,0.2,setosa,[5.2,3.4,1.4,0.2]]\n",
      "[5.2,3.5,1.5,0.2,setosa,[5.2,3.5,1.5,0.2]]\n",
      "[5.2,4.1,1.5,0.1,setosa,[5.2,4.1,1.5,0.1]]\n",
      "[5.3,3.7,1.5,0.2,setosa,[5.3,3.7,1.5,0.2]]\n",
      "[5.4,3.0,4.5,1.5,versicolor,[5.4,3.0,4.5,1.5]]\n",
      "[5.4,3.4,1.5,0.4,setosa,[5.4,3.4,1.5,0.4]]\n",
      "[5.4,3.7,1.5,0.2,setosa,[5.4,3.7,1.5,0.2]]\n",
      "[5.4,3.9,1.3,0.4,setosa,[5.4,3.9,1.3,0.4]]\n",
      "[5.4,3.9,1.7,0.4,setosa,[5.4,3.9,1.7,0.4]]\n",
      "[5.5,2.3,4.0,1.3,versicolor,[5.5,2.3,4.0,1.3]]\n",
      "[5.5,2.5,4.0,1.3,versicolor,[5.5,2.5,4.0,1.3]]\n",
      "[5.5,2.6,4.4,1.2,versicolor,[5.5,2.6,4.4,1.2]]\n",
      "[5.5,3.5,1.3,0.2,setosa,[5.5,3.5,1.3,0.2]]\n",
      "[5.5,4.2,1.4,0.2,setosa,[5.5,4.2,1.4,0.2]]\n",
      "[5.6,2.5,3.9,1.1,versicolor,[5.6,2.5,3.9,1.1]]\n",
      "[5.6,2.7,4.2,1.3,versicolor,[5.6,2.7,4.2,1.3]]\n",
      "[5.6,2.8,4.9,2.0,virginica,[5.6,2.8,4.9,2.0]]\n",
      "[5.6,3.0,4.5,1.5,versicolor,[5.6,3.0,4.5,1.5]]\n",
      "[5.7,2.5,5.0,2.0,virginica,[5.7,2.5,5.0,2.0]]\n",
      "[5.7,2.8,4.5,1.3,versicolor,[5.7,2.8,4.5,1.3]]\n",
      "[5.7,4.4,1.5,0.4,setosa,[5.7,4.4,1.5,0.4]]\n",
      "[5.8,2.7,4.1,1.0,versicolor,[5.8,2.7,4.1,1.0]]\n",
      "[5.8,2.7,5.1,1.9,virginica,[5.8,2.7,5.1,1.9]]\n",
      "[5.8,2.7,5.1,1.9,virginica,[5.8,2.7,5.1,1.9]]\n",
      "[5.8,4.0,1.2,0.2,setosa,[5.8,4.0,1.2,0.2]]\n",
      "[5.9,3.2,4.8,1.8,versicolor,[5.9,3.2,4.8,1.8]]\n",
      "[6.0,2.2,4.0,1.0,versicolor,[6.0,2.2,4.0,1.0]]\n",
      "[6.0,2.9,4.5,1.5,versicolor,[6.0,2.9,4.5,1.5]]\n",
      "[6.0,3.4,4.5,1.6,versicolor,[6.0,3.4,4.5,1.6]]\n",
      "[6.1,2.8,4.0,1.3,versicolor,[6.1,2.8,4.0,1.3]]\n",
      "[6.1,3.0,4.6,1.4,versicolor,[6.1,3.0,4.6,1.4]]\n",
      "[6.2,2.2,4.5,1.5,versicolor,[6.2,2.2,4.5,1.5]]\n",
      "[6.2,2.8,4.8,1.8,virginica,[6.2,2.8,4.8,1.8]]\n",
      "[6.2,2.9,4.3,1.3,versicolor,[6.2,2.9,4.3,1.3]]\n",
      "[6.2,3.4,5.4,2.3,virginica,[6.2,3.4,5.4,2.3]]\n",
      "[6.3,2.3,4.4,1.3,versicolor,[6.3,2.3,4.4,1.3]]\n",
      "[6.3,2.5,5.0,1.9,virginica,[6.3,2.5,5.0,1.9]]\n",
      "[6.3,2.7,4.9,1.8,virginica,[6.3,2.7,4.9,1.8]]\n",
      "[6.3,2.9,5.6,1.8,virginica,[6.3,2.9,5.6,1.8]]\n",
      "[6.3,3.3,4.7,1.6,versicolor,[6.3,3.3,4.7,1.6]]\n",
      "[6.3,3.4,5.6,2.4,virginica,[6.3,3.4,5.6,2.4]]\n",
      "[6.4,2.8,5.6,2.1,virginica,[6.4,2.8,5.6,2.1]]\n",
      "[6.4,2.8,5.6,2.2,virginica,[6.4,2.8,5.6,2.2]]\n",
      "[6.4,2.9,4.3,1.3,versicolor,[6.4,2.9,4.3,1.3]]\n",
      "[6.4,3.1,5.5,1.8,virginica,[6.4,3.1,5.5,1.8]]\n",
      "[6.4,3.2,4.5,1.5,versicolor,[6.4,3.2,4.5,1.5]]\n",
      "[6.4,3.2,5.3,2.3,virginica,[6.4,3.2,5.3,2.3]]\n",
      "[6.5,2.8,4.6,1.5,versicolor,[6.5,2.8,4.6,1.5]]\n",
      "[6.5,3.0,5.2,2.0,virginica,[6.5,3.0,5.2,2.0]]\n",
      "[6.5,3.0,5.8,2.2,virginica,[6.5,3.0,5.8,2.2]]\n",
      "[6.6,2.9,4.6,1.3,versicolor,[6.6,2.9,4.6,1.3]]\n",
      "[6.7,3.3,5.7,2.1,virginica,[6.7,3.3,5.7,2.1]]\n",
      "[6.7,3.3,5.7,2.5,virginica,[6.7,3.3,5.7,2.5]]\n",
      "[6.8,2.8,4.8,1.4,versicolor,[6.8,2.8,4.8,1.4]]\n",
      "[6.8,3.0,5.5,2.1,virginica,[6.8,3.0,5.5,2.1]]\n",
      "[6.8,3.2,5.9,2.3,virginica,[6.8,3.2,5.9,2.3]]\n",
      "[6.9,3.1,4.9,1.5,versicolor,[6.9,3.1,4.9,1.5]]\n",
      "[6.9,3.2,5.7,2.3,virginica,[6.9,3.2,5.7,2.3]]\n",
      "[7.0,3.2,4.7,1.4,versicolor,[7.0,3.2,4.7,1.4]]\n",
      "[7.2,3.0,5.8,1.6,virginica,[7.2,3.0,5.8,1.6]]\n",
      "[7.2,3.6,6.1,2.5,virginica,[7.2,3.6,6.1,2.5]]\n",
      "[7.3,2.9,6.3,1.8,virginica,[7.3,2.9,6.3,1.8]]\n",
      "[7.4,2.8,6.1,1.9,virginica,[7.4,2.8,6.1,1.9]]\n",
      "[7.6,3.0,6.6,2.1,virginica,[7.6,3.0,6.6,2.1]]\n",
      "[7.7,2.6,6.9,2.3,virginica,[7.7,2.6,6.9,2.3]]\n",
      "[7.7,2.8,6.7,2.0,virginica,[7.7,2.8,6.7,2.0]]\n",
      "[7.9,3.8,6.4,2.0,virginica,[7.9,3.8,6.4,2.0]]\n",
      "Test Data\n",
      "[4.4,3.0,1.3,0.2,setosa,[4.4,3.0,1.3,0.2]]\n",
      "[4.4,3.2,1.3,0.2,setosa,[4.4,3.2,1.3,0.2]]\n",
      "[4.6,3.2,1.4,0.2,setosa,[4.6,3.2,1.4,0.2]]\n",
      "[4.6,3.6,1.0,0.2,setosa,[4.6,3.6,1.0,0.2]]\n",
      "[4.8,3.0,1.4,0.1,setosa,[4.8,3.0,1.4,0.1]]\n",
      "[4.8,3.0,1.4,0.3,setosa,[4.8,3.0,1.4,0.3]]\n",
      "[4.8,3.1,1.6,0.2,setosa,[4.8,3.1,1.6,0.2]]\n",
      "[4.9,2.4,3.3,1.0,versicolor,[4.9,2.4,3.3,1.0]]\n",
      "[4.9,2.5,4.5,1.7,virginica,[4.9,2.5,4.5,1.7]]\n",
      "[4.9,3.6,1.4,0.1,setosa,[4.9,3.6,1.4,0.1]]\n",
      "[5.0,3.2,1.2,0.2,setosa,[5.0,3.2,1.2,0.2]]\n",
      "[5.1,2.5,3.0,1.1,versicolor,[5.1,2.5,3.0,1.1]]\n",
      "[5.1,3.5,1.4,0.2,setosa,[5.1,3.5,1.4,0.2]]\n",
      "[5.1,3.5,1.4,0.3,setosa,[5.1,3.5,1.4,0.3]]\n",
      "[5.1,3.8,1.6,0.2,setosa,[5.1,3.8,1.6,0.2]]\n",
      "[5.4,3.4,1.7,0.2,setosa,[5.4,3.4,1.7,0.2]]\n",
      "[5.5,2.4,3.7,1.0,versicolor,[5.5,2.4,3.7,1.0]]\n",
      "[5.5,2.4,3.8,1.1,versicolor,[5.5,2.4,3.8,1.1]]\n",
      "[5.6,2.9,3.6,1.3,versicolor,[5.6,2.9,3.6,1.3]]\n",
      "[5.6,3.0,4.1,1.3,versicolor,[5.6,3.0,4.1,1.3]]\n",
      "[5.7,2.6,3.5,1.0,versicolor,[5.7,2.6,3.5,1.0]]\n",
      "[5.7,2.8,4.1,1.3,versicolor,[5.7,2.8,4.1,1.3]]\n",
      "[5.7,2.9,4.2,1.3,versicolor,[5.7,2.9,4.2,1.3]]\n",
      "[5.7,3.0,4.2,1.2,versicolor,[5.7,3.0,4.2,1.2]]\n",
      "[5.7,3.8,1.7,0.3,setosa,[5.7,3.8,1.7,0.3]]\n",
      "[5.8,2.6,4.0,1.2,versicolor,[5.8,2.6,4.0,1.2]]\n",
      "[5.8,2.7,3.9,1.2,versicolor,[5.8,2.7,3.9,1.2]]\n",
      "[5.8,2.8,5.1,2.4,virginica,[5.8,2.8,5.1,2.4]]\n",
      "[5.9,3.0,4.2,1.5,versicolor,[5.9,3.0,4.2,1.5]]\n",
      "[5.9,3.0,5.1,1.8,virginica,[5.9,3.0,5.1,1.8]]\n",
      "[6.0,2.2,5.0,1.5,virginica,[6.0,2.2,5.0,1.5]]\n",
      "[6.0,2.7,5.1,1.6,versicolor,[6.0,2.7,5.1,1.6]]\n",
      "[6.0,3.0,4.8,1.8,virginica,[6.0,3.0,4.8,1.8]]\n",
      "[6.1,2.6,5.6,1.4,virginica,[6.1,2.6,5.6,1.4]]\n",
      "[6.1,2.8,4.7,1.2,versicolor,[6.1,2.8,4.7,1.2]]\n",
      "[6.1,2.9,4.7,1.4,versicolor,[6.1,2.9,4.7,1.4]]\n",
      "[6.1,3.0,4.9,1.8,virginica,[6.1,3.0,4.9,1.8]]\n",
      "[6.3,2.5,4.9,1.5,versicolor,[6.3,2.5,4.9,1.5]]\n",
      "[6.3,2.8,5.1,1.5,virginica,[6.3,2.8,5.1,1.5]]\n",
      "[6.3,3.3,6.0,2.5,virginica,[6.3,3.3,6.0,2.5]]\n",
      "[6.4,2.7,5.3,1.9,virginica,[6.4,2.7,5.3,1.9]]\n",
      "[6.5,3.0,5.5,1.8,virginica,[6.5,3.0,5.5,1.8]]\n",
      "[6.5,3.2,5.1,2.0,virginica,[6.5,3.2,5.1,2.0]]\n",
      "[6.6,3.0,4.4,1.4,versicolor,[6.6,3.0,4.4,1.4]]\n",
      "[6.7,2.5,5.8,1.8,virginica,[6.7,2.5,5.8,1.8]]\n",
      "[6.7,3.0,5.0,1.7,versicolor,[6.7,3.0,5.0,1.7]]\n",
      "[6.7,3.0,5.2,2.3,virginica,[6.7,3.0,5.2,2.3]]\n",
      "[6.7,3.1,4.4,1.4,versicolor,[6.7,3.1,4.4,1.4]]\n",
      "[6.7,3.1,4.7,1.5,versicolor,[6.7,3.1,4.7,1.5]]\n",
      "[6.7,3.1,5.6,2.4,virginica,[6.7,3.1,5.6,2.4]]\n",
      "[6.9,3.1,5.1,2.3,virginica,[6.9,3.1,5.1,2.3]]\n",
      "[6.9,3.1,5.4,2.1,virginica,[6.9,3.1,5.4,2.1]]\n",
      "[7.1,3.0,5.9,2.1,virginica,[7.1,3.0,5.9,2.1]]\n",
      "[7.2,3.2,6.0,1.8,virginica,[7.2,3.2,6.0,1.8]]\n",
      "[7.7,3.0,6.1,2.3,virginica,[7.7,3.0,6.1,2.3]]\n",
      "[7.7,3.8,6.7,2.2,virginica,[7.7,3.8,6.7,2.2]]\n"
     ]
    }
   ],
   "source": [
    "val Array(trainingData, testData) = Data.randomSplit(Array(0.7, 0.3))\n",
    "println(\"Training Data\")\n",
    "trainingData.take(100).foreach(println)\n",
    "println(\"Test Data\")\n",
    "testData.take(100).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are widely used since they are easy to interpret, handle categorical features, extend to the multiclass classification setting, do not require feature scaling and are able to capture nonlinearities and feature interactions. Tree ensemble algorithms such as random forests and boosting are among the top performers for classification and regression tasks.\n",
    "MLlib supports decision trees for binary and multiclass classification and for regression, using both continuous and categorical features. The implementation partitions data by rows, allowing distributed training with millions of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val dt = new DecisionTreeClassifier().setLabelCol(\"indexedLabel\").setFeaturesCol(\"indexedFeatures\")\n",
    "// Convert indexed labels back to original labels.\n",
    "val labelConverter = new IndexToString().setInputCol(\"prediction\").setOutputCol(\"predictedLabel\").setLabels(labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Chain indexers and tree in a Pipeline.\n",
    "val pipeline = new Pipeline().setStages(Array(labelIndexer, featureIndexer, dt, labelConverter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned classification tree model:\n",
      "DecisionTreeClassificationModel (uid=dtc_e0ac8db8e732) of depth 4 with 11 nodes\n",
      "  If (feature 2 <= 1.9)\n",
      "   Predict: 2.0\n",
      "  Else (feature 2 > 1.9)\n",
      "   If (feature 2 <= 4.8)\n",
      "    If (feature 3 <= 1.6)\n",
      "     Predict: 0.0\n",
      "    Else (feature 3 > 1.6)\n",
      "     If (feature 0 <= 5.9)\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 > 5.9)\n",
      "      Predict: 1.0\n",
      "   Else (feature 2 > 4.8)\n",
      "    If (feature 3 <= 1.5)\n",
      "     Predict: 0.0\n",
      "    Else (feature 3 > 1.5)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val model = pipeline.fit(trainingData)\n",
    "val treeModel = model.stages(2).asInstanceOf[DecisionTreeClassificationModel]\n",
    "println(\"Learned classification tree model:\\n\" + treeModel.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+-----------------+\n",
      "|predictedLabel|Species|         features|\n",
      "+--------------+-------+-----------------+\n",
      "|        setosa| setosa|[4.4,3.0,1.3,0.2]|\n",
      "|        setosa| setosa|[4.4,3.2,1.3,0.2]|\n",
      "|        setosa| setosa|[4.6,3.2,1.4,0.2]|\n",
      "|        setosa| setosa|[4.6,3.6,1.0,0.2]|\n",
      "|        setosa| setosa|[4.8,3.0,1.4,0.1]|\n",
      "+--------------+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- SepalLength: double (nullable = true)\n",
      " |-- SepalWidth: double (nullable = true)\n",
      " |-- PetalLength: double (nullable = true)\n",
      " |-- PetalWidth: double (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- indexedLabel: double (nullable = true)\n",
      " |-- indexedFeatures: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      " |-- predictedLabel: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Make predictions.\n",
    "val predictions = model.transform(testData)\n",
    "// Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"Species\", \"features\").show(5)\n",
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.1071428571428571\n",
      "Learned classification tree model:\n",
      "DecisionTreeClassificationModel (uid=dtc_e0ac8db8e732) of depth 4 with 11 nodes\n",
      "  If (feature 2 <= 1.9)\n",
      "   Predict: 2.0\n",
      "  Else (feature 2 > 1.9)\n",
      "   If (feature 2 <= 4.8)\n",
      "    If (feature 3 <= 1.6)\n",
      "     Predict: 0.0\n",
      "    Else (feature 3 > 1.6)\n",
      "     If (feature 0 <= 5.9)\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 > 5.9)\n",
      "      Predict: 1.0\n",
      "   Else (feature 2 > 4.8)\n",
      "    If (feature 3 <= 1.5)\n",
      "     Predict: 0.0\n",
      "    Else (feature 3 > 1.5)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Select (prediction, true label) and compute test error.\n",
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(\"indexedLabel\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val accuracy = evaluator.evaluate(predictions)\n",
    "println(\"Test Error = \" + (1.0 - accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "19.0  2.0   0.0   \n",
      "4.0   17.0  0.0   \n",
      "0.0   0.0   14.0  \n",
      "Summary Statistics\n",
      "Precision = 0.8928571428571429\n",
      "Recall = 0.8928571428571429\n",
      "F1 Score = 0.8928571428571429\n",
      "Precision(0.0) = 0.8260869565217391\n",
      "Precision(1.0) = 0.8947368421052632\n",
      "Precision(2.0) = 1.0\n",
      "Recall(0.0) = 0.9047619047619048\n",
      "Recall(1.0) = 0.8095238095238095\n",
      "Recall(2.0) = 1.0\n",
      "FPR(0.0) = 0.11428571428571428\n",
      "FPR(1.0) = 0.05714285714285714\n",
      "FPR(2.0) = 0.0\n",
      "F1-Score(0.0) = 0.8636363636363636\n",
      "F1-Score(1.0) = 0.8500000000000001\n",
      "F1-Score(2.0) = 1.0\n",
      "Weighted precision: 0.895308924485126\n",
      "Weighted recall: 0.8928571428571428\n",
      "Weighted F1 score: 0.8926136363636363\n",
      "Weighted false positive rate: 0.06428571428571428\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "val predictionRDD = predictions.select(\"prediction\", \"indexedLabel\").as[(Double,Double)].rdd\n",
    "val metrics = new MulticlassMetrics(predictionRDD)\n",
    "// Confusion matrix\n",
    "println(\"Confusion matrix:\")\n",
    "println(metrics.confusionMatrix)\n",
    "\n",
    "// Overall Statistics\n",
    "val precision = metrics.precision\n",
    "val recall = metrics.recall // same as true positive rate\n",
    "val f1Score = metrics.fMeasure\n",
    "println(\"Summary Statistics\")\n",
    "println(s\"Precision = $precision\")\n",
    "println(s\"Recall = $recall\")\n",
    "println(s\"F1 Score = $f1Score\")\n",
    "\n",
    "// Precision by label\n",
    "val labels = metrics.labels\n",
    "labels.foreach { l =>\n",
    "    println(s\"Precision($l) = \" + metrics.precision(l))\n",
    "}\n",
    "\n",
    "// Recall by label\n",
    "labels.foreach { l =>\n",
    "    println(s\"Recall($l) = \" + metrics.recall(l))\n",
    "}\n",
    "\n",
    "// False positive rate by label\n",
    "labels.foreach { l =>\n",
    "    println(s\"FPR($l) = \" + metrics.falsePositiveRate(l))\n",
    "}\n",
    "\n",
    "// F-measure by label\n",
    "labels.foreach { l =>\n",
    "    println(s\"F1-Score($l) = \" + metrics.fMeasure(l))\n",
    "}\n",
    "\n",
    "// Weighted stats\n",
    "println(s\"Weighted precision: ${metrics.weightedPrecision}\")\n",
    "println(s\"Weighted recall: ${metrics.weightedRecall}\")\n",
    "println(s\"Weighted F1 score: ${metrics.weightedFMeasure}\")\n",
    "println(s\"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a simple multiclass classification algorithm with the assumption of independence between every pair of features. Naive Bayes can be trained very efficiently. Within a single pass to the training data, it computes the conditional probability distribution of each feature given label, and then it applies Bayes theorem to compute the conditional probability distribution of label given an observation and use it for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.NaiveBayes\n",
    "val nb = new NaiveBayes().setLabelCol(\"indexedLabel\").setFeaturesCol(\"indexedFeatures\")\n",
    "// Convert indexed labels back to original labels.\n",
    "val labelConverter = new IndexToString().setInputCol(\"prediction\").setOutputCol(\"predictedLabel\").setLabels(labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Chain indexers and tree in a Pipeline.\n",
    "val pipeline = new Pipeline().setStages(Array(labelIndexer, featureIndexer, nb, labelConverter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val nbmodel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Make predictions.\n",
    "val predictions = nbmodel.transform(testData)\n",
    "// Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"Species\", \"features\").show(5)\n",
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Select (prediction, true label) and compute test error.\n",
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(\"indexedLabel\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val accuracy = evaluator.evaluate(predictions)\n",
    "// val treeModel = model.stages(2).asInstanceOf[DecisionTreeClassificationModel]\n",
    "// println(\"Learned Naive Bayesmodel:\\n\" + treeModel.toDebugString)\n",
    "println(\"Test Error = \" + (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Complete evaluation on test set for Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "val predictionRDD = predictions.select(\"prediction\", \"indexedLabel\").as[(Double,Double)].rdd\n",
    "val metrics = new MulticlassMetrics(predictionRDD)\n",
    "// Confusion matrix\n",
    "println(\"Confusion matrix:\")\n",
    "println(metrics.confusionMatrix)\n",
    "\n",
    "// Overall Statistics\n",
    "val precision = metrics.precision\n",
    "val recall = metrics.recall // same as true positive rate\n",
    "val f1Score = metrics.fMeasure\n",
    "println(\"Summary Statistics\")\n",
    "println(s\"Precision = $precision\")\n",
    "println(s\"Recall = $recall\")\n",
    "println(s\"F1 Score = $f1Score\")\n",
    "\n",
    "// Precision by label\n",
    "val labels = metrics.labels\n",
    "labels.foreach { l =>\n",
    "    println(s\"Precision($l) = \" + metrics.precision(l))\n",
    "}\n",
    "\n",
    "// Recall by label\n",
    "labels.foreach { l =>\n",
    "    println(s\"Recall($l) = \" + metrics.recall(l))\n",
    "}\n",
    "\n",
    "// False positive rate by label\n",
    "labels.foreach { l =>\n",
    "    println(s\"FPR($l) = \" + metrics.falsePositiveRate(l))\n",
    "}\n",
    "\n",
    "// F-measure by label\n",
    "labels.foreach { l =>\n",
    "    println(s\"F1-Score($l) = \" + metrics.fMeasure(l))\n",
    "}\n",
    "\n",
    "// Weighted stats\n",
    "println(s\"Weighted precision: ${metrics.weightedPrecision}\")\n",
    "println(s\"Weighted recall: ${metrics.weightedRecall}\")\n",
    "println(s\"Weighted F1 score: ${metrics.weightedFMeasure}\")\n",
    "println(s\"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
